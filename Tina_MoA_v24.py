#!/usr/bin/env python3
# Tina Real Execution â€“ v17.0 ã€ˆæ”¹è¿›ç‰ˆã€‰
# ------------------------------------------------------------
# æ ¸å¿ƒæ”¹è¿›
# 1. è¯„åˆ†æ˜¾ç¤ºä¼˜åŒ–ï¼šæ˜¾ç¤ºæ¯ä¸ªæ¨¡å‹çš„åç§°å’Œå…·ä½“åˆ†æ•°
# 2. é”™è¯¯å¤„ç†å¢å¼ºï¼šç¡®ä¿æ‰€æœ‰5ä¸ªæ¨¡å‹éƒ½å‚ä¸è¯„åˆ†
# 3. æ‰§è¡Œæ•ˆç‡æå‡ï¼šç®€åŒ–ä»»åŠ¡ç›´æ¥æ‰§è¡Œï¼Œå‡å°‘å¾ªç¯
# 4. æ—¥å¿—è®°å½•æ”¹è¿›ï¼šè®°å½•æ¯ä¸ªæ¨¡å‹çš„è¯¦ç»†å“åº”
# 5. æ™ºèƒ½ä»»åŠ¡è¯†åˆ«ï¼šç®€å•ä»»åŠ¡è·³è¿‡å¤æ‚æµç¨‹
# (Revisions from Coding Partner to fix premature completion)
# ------------------------------------------------------------
import os, sys, asyncio, json, re, subprocess, glob, shutil
from datetime import datetime
from typing import List, Literal, Dict, Any, Tuple
from collections import Counter, defaultdict
import traceback

import numpy as np
from rich.console import Console
from rich.panel import Panel
from rich.text import Text
from rich.live import Live
from rich.spinner import Spinner
from rich.table import Table
from rich.columns import Columns
import together

# ---------- å¸¸é‡ & é…ç½® ----------
REFERENCE_MODELS = [
    "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
    "mistralai/Mixtral-8x7B-Instruct-v0.1",
    "deepseek-ai/DeepSeek-V3",
]

AGGREGATOR_MODEL = "deepseek-ai/DeepSeek-V3"
CRITIC_MODELS = [
    "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
    "mistralai/Mixtral-8x7B-Instruct-v0.1",
    "deepseek-ai/DeepSeek-V3",
]

EXPERT_MODEL = "deepseek-ai/DeepSeek-V3"

State = Literal["DISCOVER_FILES", "INSTALL_TOOLS", "RUN_QC", "REPORT", "DONE"]
PIPELINE_ORDER: List[State] = ["DISCOVER_FILES","INSTALL_TOOLS","RUN_QC","REPORT","DONE"]

# ç®€åŒ–çš„æç¤ºè¯
PLANNER_SYSTEM_PROMPT = """You are a bioinformatics consultant. Output ONE concise sub-task to advance the pipeline.
States: DISCOVER_FILES â†’ INSTALL_TOOLS â†’ RUN_QC â†’ REPORT â†’ DONE
If state=="DONE" and validated==true, output TERMINATE."""

AGGREGATOR_SYSTEM_PROMPT = "Merge suggestions into ONE concise actionable sub-task."
SELF_CRITIQUE_SYSTEM_PROMPT = "Point out one concrete flaw or risk."
CRITIC_SYSTEM_PROMPT = """Score the plan 0-10. Return ONLY: {"score":N,"reason":"one sentence"}"""
EXPERT_SYSTEM_PROMPT = """React agent. Return ONLY JSON:
{"thought":"...","action":{"tool_name":"execute_bash|task_complete","parameters":{...}}}
Only use 'task_complete' when the specific sub-task is fully accomplished.
"""

# ç®€å•ä»»åŠ¡æ£€æµ‹
SIMPLE_TASK_PATTERNS = [
    r"generate.*fastq",
    r"create.*file",
    r"ç”Ÿæˆ.*æ–‡ä»¶",
    r"make.*reads"
]

API_KEY = os.getenv("TOGETHER_API_KEY") or os.getenv("TINA_API_KEY") 
if not API_KEY:
    API_KEY = "92d5979f5ffc69d344a37cc7b2cbef622b6d51b9a24f984d97a68ece985384fb"

TIMEOUT_CMD = 300  # å‡å°‘è¶…æ—¶æ—¶é—´
MAX_PLANNER_ROUNDS = 10  # å‡å°‘æœ€å¤§è½®æ•°
MAX_REACT_STEPS = 15  # å‡å°‘Reactæ­¥éª¤
CRITIC_PASS = 7  # é™ä½é€šè¿‡é—¨æ§›
MAX_TOKENS_PER_TURN = 3000  # å‡å°‘tokenæ•°

console = Console()
log_dir = "tina_logs"
os.makedirs(log_dir, exist_ok=True)
log_file = os.path.join(log_dir, f"tina_v17_{datetime.now():%Y%m%d_%H%M%S}.log")

def log(msg: str):
    """å¢å¼ºçš„æ—¥å¿—åŠŸèƒ½"""
    timestamp = datetime.now().strftime("%H:%M:%S.%f")[:-3]
    log_entry = f"[{timestamp}] {msg}"
    with open(log_file, "a", encoding="utf-8") as f:
        f.write(log_entry + "\n")
    # ä¹Ÿæ‰“å°åˆ°æ§åˆ¶å°ç”¨äºè°ƒè¯•
    if "ERROR" in msg or "WARN" in msg:
        console.print(f"[red]{log_entry}[/red]", highlight=False)

def panel(content: str, title: str, style: str = "white"):
    """æ˜¾ç¤ºé¢æ¿å¹¶è®°å½•æ—¥å¿—"""
    console.print(Panel(Text(content, overflow="fold"), title=title, border_style=style, expand=True))
    log(f"{title}: {content[:2000]}")

def run_bash(cmd: str) -> str:
    """æ‰§è¡Œbashå‘½ä»¤"""
    panel(f"$ {cmd}", "ğŸ’» æ‰§è¡Œå‘½ä»¤", "cyan")
    try:
        proc = subprocess.Popen(
            cmd, shell=True, 
            stdout=subprocess.PIPE, stderr=subprocess.PIPE,
            executable="/bin/bash", text=True, 
            encoding="utf-8", errors="replace"
        )
        out, err = proc.communicate(timeout=TIMEOUT_CMD)
        result = f"[STDOUT]\n{out}\n[STDERR]\n{err}".strip()
        style = "red" if err.strip() and proc.returncode != 0 else "green"
        panel(result[:1000], "ğŸ–¥ï¸ å‘½ä»¤è¾“å‡º", style)
        return result
    except subprocess.TimeoutExpired:
        proc.kill()
        return "[ERROR] Command timeout"
    except Exception as e:
        return f"[ERROR] {str(e)}"

# å¼‚æ­¥å®¢æˆ·ç«¯
async_client = together.AsyncClient(api_key=API_KEY, timeout=60)

async def llm(model: str, system: str, user: str, temperature: float = 0.3, max_tokens: int = 1000) -> str:
    """è°ƒç”¨LLM"""
    try:
        resp = await async_client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system},
                {"role": "user", "content": user}
            ],
            temperature=temperature,
            max_tokens=max_tokens
        )
        msg = resp.choices[0].message.content.strip()
        log(f"[{model}] Response: {msg[:200]}...")
        return msg
    except Exception as e:
        error_msg = f"ERROR calling {model}: {str(e)}"
        log(error_msg)
        return error_msg

def is_simple_task(goal: str) -> bool:
    """æ£€æµ‹æ˜¯å¦ä¸ºç®€å•ä»»åŠ¡"""
    goal_lower = goal.lower()
    return any(re.search(pattern, goal_lower) for pattern in SIMPLE_TASK_PATTERNS)

def parse_json_score(txt: str) -> Tuple[int, str]:
    """è§£æè¯„åˆ†JSONï¼Œè¿”å›(åˆ†æ•°, åŸå› )"""
    try:
        # é¦–å…ˆå°è¯•æå–JSON
        json_match = re.search(r'\{[^}]*"score"[^}]*\}', txt, re.DOTALL)
        if json_match:
            obj = json.loads(json_match.group(0))
            return int(obj.get("score", -1)), obj.get("reason", "No reason")
    except:
        pass
    
    # å¤‡ç”¨ï¼šæŸ¥æ‰¾æ•°å­—
    score_match = re.search(r'\b([0-9]|10)\b', txt)
    score = int(score_match.group(1)) if score_match else -1
    return score, "Failed to parse reason"

async def critic_vote_enhanced(goal: str, plan: str) -> Tuple[bool, List[Dict]]:
    """å¢å¼ºçš„è¯„å®¡å›¢æŠ•ç¥¨ï¼Œè¿”å›è¯¦ç»†ä¿¡æ¯"""
    prompt = f"Goal: {goal}\nPlan: {plan}"
    
    # åˆ›å»ºè¯„åˆ†è¡¨æ ¼
    score_table = Table(title="ğŸ—³ï¸ è¯„å®¡å›¢è¯¦ç»†è¯„åˆ†", show_header=True, expand=True)
    score_table.add_column("æ¨¡å‹", style="cyan", width=40)
    score_table.add_column("åˆ†æ•°", style="yellow", width=10)
    score_table.add_column("ç†ç”±", style="white", width=50)
    
    with Live(Spinner("dots", text="è¯„å®¡å›¢æŠ•ç¥¨ä¸­..."), console=console, transient=True):
        # å¹¶è¡Œè°ƒç”¨æ‰€æœ‰è¯„å®¡æ¨¡å‹
        tasks = []
        for i, model in enumerate(CRITIC_MODELS):
            task = llm(model, CRITIC_SYSTEM_PROMPT, prompt, temperature=0, max_tokens=200)
            tasks.append((i, model, task))
        
        # æ”¶é›†ç»“æœ
        results = []
        for i, model, task in tasks:
            try:
                response = await task
                score, reason = parse_json_score(response)
                results.append({
                    "model": model,
                    "score": score,
                    "reason": reason,
                    "response": response
                })
                
                # æ·»åŠ åˆ°è¡¨æ ¼
                model_short = model.split('/')[-1][:35] + "..." if len(model.split('/')[-1]) > 35 else model.split('/')[-1]
                score_table.add_row(
                    model_short,
                    str(score) if score >= 0 else "ERROR",
                    reason[:47] + "..." if len(reason) > 47 else reason
                )
                
            except Exception as e:
                log(f"ERROR in critic {i} ({model}): {str(e)}")
                results.append({
                    "model": model,
                    "score": -1,
                    "reason": f"Error: {str(e)}",
                    "response": str(e)
                })
                score_table.add_row(
                    model.split('/')[-1],
                    "ERROR",
                    str(e)[:50]
                )
    
    # æ˜¾ç¤ºè¯¦ç»†è¯„åˆ†è¡¨
    console.print(score_table)
    
    # è®¡ç®—æœ‰æ•ˆåˆ†æ•°
    valid_scores = [r["score"] for r in results if r["score"] >= 0]
    
    if valid_scores:
        mean = np.mean(valid_scores)
        std = np.std(valid_scores) if len(valid_scores) > 1 else 0
        median = np.median(valid_scores)
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        stats_panel = Panel(
            f"æœ‰æ•ˆè¯„åˆ†: {len(valid_scores)}/{len(CRITIC_MODELS)}\n"
            f"åˆ†æ•°åˆ—è¡¨: {valid_scores}\n"
            f"å¹³å‡åˆ†: {mean:.2f} Â± {std:.2f}\n"
            f"ä¸­ä½æ•°: {median:.1f}\n"
            f"{'âœ… é€šè¿‡' if mean >= CRITIC_PASS else 'âŒ æœªé€šè¿‡'} (åŠæ ¼çº¿: {CRITIC_PASS})",
            title="ğŸ“Š è¯„åˆ†ç»Ÿè®¡",
            border_style="green" if mean >= CRITIC_PASS else "red"
        )
        console.print(stats_panel)
        
        passed = mean >= CRITIC_PASS
    else:
        panel("æ‰€æœ‰è¯„å®¡æ¨¡å‹éƒ½å¤±è´¥äº†ï¼", "âš ï¸ è­¦å‘Š", "yellow")
        passed = False
    
    return passed, results

async def simple_task_execution(goal: str) -> bool:
    """ç›´æ¥æ‰§è¡Œç®€å•ä»»åŠ¡"""
    panel(f"æ£€æµ‹åˆ°ç®€å•ä»»åŠ¡ï¼Œç›´æ¥æ‰§è¡Œï¼š{goal}", "ğŸš€ å¿«é€Ÿæ¨¡å¼", "green")
    
    # å¯¹äºç”Ÿæˆfastqæ–‡ä»¶çš„ä»»åŠ¡
    if "fastq" in goal.lower() or "generate" in goal.lower():
        # ç”Ÿæˆä¸€ä¸ªç®€å•çš„fastqæ–‡ä»¶
        cmd = """
# ç”Ÿæˆéšæœºfastqæ–‡ä»¶
cat > generate_random_fastq.py << 'EOF'
import random
import sys

def generate_random_seq(length):
    return ''.join(random.choice('ACGT') for _ in range(length))

def generate_random_qual(length):
    return ''.join(chr(random.randint(33, 73)) for _ in range(length))

# ç”Ÿæˆ1000ä¸ªreads
num_reads = 1000
read_length = 150

with open('random_reads_R1.fastq', 'w') as f1, open('random_reads_R2.fastq', 'w') as f2:
    for i in range(num_reads):
        seq1 = generate_random_seq(read_length)
        seq2 = generate_random_seq(read_length)
        qual1 = generate_random_qual(read_length)
        qual2 = generate_random_qual(read_length)
        
        # R1
        f1.write(f'@read_{i}/1\\n{seq1}\\n+\\n{qual1}\\n')
        # R2
        f2.write(f'@read_{i}/2\\n{seq2}\\n+\\n{qual2}\\n')

print(f"Generated {num_reads} paired-end reads")
print("Files: random_reads_R1.fastq, random_reads_R2.fastq")
EOF

python generate_random_fastq.py
ls -lh random_reads_*.fastq
head -n 8 random_reads_R1.fastq
"""
        result = run_bash(cmd)
        
        if "Generated" in result and "random_reads" in result:
            panel("âœ… æˆåŠŸç”ŸæˆéšæœºFASTQæ–‡ä»¶ï¼", "ğŸ‰ ä»»åŠ¡å®Œæˆ", "green")
            return True
    
    return False

async def react_execute_improved(sub_task: str, project_state: Dict[str, Any]) -> bool:
    """æ”¹è¿›çš„ReActæ‰§è¡Œï¼Œè¿”å›æ˜¯å¦æˆåŠŸ"""
    history = ""
    
    # Let's give the agent a few more steps to work with.
    for step in range(1, MAX_REACT_STEPS + 1): 
        if step == 1:
            panel(f"å­ä»»åŠ¡: {sub_task}", "ğŸ¯ å¼€å§‹æ‰§è¡Œ", "bold green")
        
        # Add more context to the prompt for better decisions
        prompt = (f"Current State: {project_state['state']}\n"
                  f"Overall Goal: {project_state['user_goal']}\n"
                  f"Sub-Task: {sub_task}\n\n"
                  f"History of previous steps (use this to inform your next action):\n{history[-1500:]}")
        
        with Live(Spinner("bouncingBar", text=f"æ€è€ƒæ­¥éª¤ {step}/{MAX_REACT_STEPS}..."), console=console, transient=True):
            resp = await llm(EXPERT_MODEL, EXPERT_SYSTEM_PROMPT, prompt, temperature=0)
        
        # --- Action Parsing Logic (remains the same) ---
        try:
            data = None
            json_match = re.search(r'\{.*"thought".*"action".*\}', resp, re.DOTALL)
            if json_match:
                data = json.loads(json_match.group(0))
            else:
                # Handle cases where the model doesn't return valid JSON
                panel(f"Could not find valid JSON in response. Trying to continue.\nResponse: {resp[:200]}", f"âš ï¸ è­¦å‘Š ({step})", "yellow")
                history += f"\n[Step {step}] Invalid response from model."
                continue
        except Exception as e:
            panel(f"JSONè§£æå¤±è´¥: {str(e)}\nå“åº”: {resp[:200]}", "âŒ é”™è¯¯", "red")
            history += f"\n[Step {step}] Failed to parse JSON."
            continue
        
        thought = data.get("thought", "No thought provided.")
        action = data.get("action", {})
        tool = action.get("tool_name", "")
        params = action.get("parameters", {})
        
        panel(thought, f"ğŸ¤” æ€è€ƒ ({step})", "green")
        
        # --- Core Logic Change is Here ---
        if tool == "execute_bash":
            cmd = params.get("cmd") or params.get("command") or params.get("script", "")
            if cmd:
                result = run_bash(cmd)
                # Append the outcome to the history for the next step
                history += f"\n[Step {step} Observation]: Executed `{cmd}`\n{result[:500]}"
            else:
                history += f"\n[Step {step} Observation]: Model chose execute_bash but provided no command."

        elif tool == "task_complete":
            reason = params.get("reason", "No reason given.")
            panel(f"Agent decided the sub-task is complete. Reason: {reason}", "âœ… å­ä»»åŠ¡ç¡®è®¤å®Œæˆ", "bold green")
            return True # This is the ONLY place we should return True

        else:
            panel(f"Unknown tool: {tool}", f"âŒ é”™è¯¯ ({step})", "red")
            history += f"\n[Step {step} Observation]: Agent chose an invalid tool '{tool}'."

    # If the loop finishes without `task_complete` being called, the sub-task failed.
    panel("Agent reached max steps without completing the sub-task.", "âŒ å­ä»»åŠ¡å¤±è´¥", "red")
    return False

async def main():
    """ä¸»å‡½æ•°"""
    console.print(Panel(
        "[bold cyan]Tina v17.0 â€“ æ”¹è¿›ç‰ˆ MoA Agent[/bold cyan]\n"
        "â€¢ è¯¦ç»†è¯„åˆ†æ˜¾ç¤º\n"
        "â€¢ ç®€å•ä»»åŠ¡å¿«é€Ÿæ‰§è¡Œ\n"
        "â€¢ æ›´é«˜æ•ˆçš„æ‰§è¡Œæµç¨‹",
        border_style="blue"
    ))
    
    while True:
        try:
            goal = console.input("\n[bold yellow]ğŸ§‘ è¯·è¾“å…¥ä»»åŠ¡ç›®æ ‡ï¼š[/bold yellow]").strip()
            if goal.lower() in ("exit", "quit", "q"):
                break
            
            log(f"User goal: {goal}")
            
            # æ£€æµ‹ç®€å•ä»»åŠ¡
            if is_simple_task(goal):
                success = await simple_task_execution(goal)
                if success:
                    continue
            
            # å¤æ‚ä»»åŠ¡æµç¨‹
            project_state = {
                "user_goal": goal,
                "state": "DISCOVER_FILES",
                "validated": False
            }
            
            for round_id in range(1, MAX_PLANNER_ROUNDS + 1):
                panel(f"ç¬¬ {round_id}/{MAX_PLANNER_ROUNDS} è½®", "â­ è§„åˆ’è½®æ¬¡", "bold magenta")
                
                # è§„åˆ’æ­¥éª¤
                payload = json.dumps(project_state, indent=2)
                
                # è·å–ä¸“å®¶æ„è§ï¼ˆç®€åŒ–ç‰ˆï¼‰
                with Live(Spinner("dots", text="ä¸“å®¶æ€è€ƒä¸­..."), console=console, transient=True):
                    opinions = await asyncio.gather(*[
                        llm(m, PLANNER_SYSTEM_PROMPT, 
                            f"State: {project_state}\nGoal: {goal}\nGive ONE next action.")
                        for m in REFERENCE_MODELS[:2]  # åªç”¨2ä¸ªæ¨¡å‹åŠ å¿«é€Ÿåº¦
                    ])
                
                # èšåˆæ„è§
                final_plan = await llm(
                    AGGREGATOR_MODEL, 
                    AGGREGATOR_SYSTEM_PROMPT,
                    "\n".join(opinions)
                )
                
                panel(final_plan, "ğŸ“„ æœ€ç»ˆæ–¹æ¡ˆ", "blue")
                
                # æ£€æŸ¥æ˜¯å¦å®Œæˆ
                if "TERMINATE" in final_plan.upper():
                    panel("ğŸ† ä»»åŠ¡å®Œæˆï¼", "ğŸ‰ æˆåŠŸ", "bold green")
                    break
                
                # è¯„å®¡æŠ•ç¥¨
                passed, vote_details = await critic_vote_enhanced(goal, final_plan)
                
                if not passed:
                    panel("æ–¹æ¡ˆæœªé€šè¿‡ï¼Œç»§ç»­ä¼˜åŒ–...", "âŒ éœ€è¦æ”¹è¿›", "red")
                    continue
                
                # æ‰§è¡Œè®¡åˆ’
                success = await react_execute_improved(final_plan, project_state)
                
                # æ›´æ–°çŠ¶æ€
                if success:
                    panel(f"Sub-task for state '{project_state['state']}' was successful.", "âœ… çŠ¶æ€æ¨è¿›", "bold green")
                    current_idx = PIPELINE_ORDER.index(project_state['state'])
                    
                    if current_idx < len(PIPELINE_ORDER) - 1:
                        next_state = PIPELINE_ORDER[current_idx + 1]
                        project_state['state'] = next_state
                        panel(f"Advancing to next state: {next_state}", "ğŸ”„ æµç¨‹æ›´æ–°", "magenta")
                        
                        # Check if we have just moved to the final state
                        if next_state == "DONE":
                            project_state["validated"] = True
                            panel("âœ… All pipeline states completed. Task is successful!", "ğŸŠ ä»»åŠ¡æˆåŠŸ", "bold green")
                            break
                    else:
                        # This means we were already at the DONE state
                        project_state["validated"] = True
                        panel("âœ… Final state 'DONE' was re-validated. Task is successful!", "ğŸŠ ä»»åŠ¡æˆåŠŸ", "bold green")
                        break
                else:
                    # This branch is new. It handles the case where a sub-task fails.
                    panel(f"Sub-task for state '{project_state['state']}' failed to complete.", "âŒ çŠ¶æ€åœæ»", "red")
                    panel("The agent will try to re-plan in the next round.", "ğŸ¤” é‡æ–°è§„åˆ’", "yellow")

            else: # This else belongs to the for loop
                panel("è¾¾åˆ°æœ€å¤§è½®æ¬¡é™åˆ¶", "âš ï¸ è¶…æ—¶", "yellow")
                
        except KeyboardInterrupt:
            panel("ç”¨æˆ·ä¸­æ–­", "âš ï¸ é€€å‡º", "yellow")
            break
        except Exception as e:
            panel(f"é”™è¯¯: {str(e)}\n{traceback.format_exc()}", "âŒ å¼‚å¸¸", "red")
            
    # æ˜¾ç¤ºæ—¥å¿—ä½ç½®
    panel(f"è¯¦ç»†æ—¥å¿—ä¿å­˜åœ¨: {log_file}", "ğŸ“ æ—¥å¿—æ–‡ä»¶", "dim")

if __name__ == "__main__":
    asyncio.run(main())
