#!/usr/bin/env python3
# Tina Real Execution â€“ v17.0 ã€ˆæ”¹è¿›ç‰ˆã€‰
# ------------------------------------------------------------
# æ ¸å¿ƒæ”¹è¿›
# 1. è¯„åˆ†æ˜¾ç¤ºä¼˜åŒ–ï¼šæ˜¾ç¤ºæ¯ä¸ªæ¨¡å‹çš„åç§°å’Œå…·ä½“åˆ†æ•°
# 2. é”™è¯¯å¤„ç†å¢å¼ºï¼šç¡®ä¿æ‰€æœ‰5ä¸ªæ¨¡å‹éƒ½å‚ä¸è¯„åˆ†
# 3. æ‰§è¡Œæ•ˆç‡æå‡ï¼šç®€åŒ–ä»»åŠ¡ç›´æ¥æ‰§è¡Œï¼Œå‡å°‘å¾ªç¯
# 4. æ—¥å¿—è®°å½•æ”¹è¿›ï¼šè®°å½•æ¯ä¸ªæ¨¡å‹çš„è¯¦ç»†å“åº”
# 5. æ™ºèƒ½ä»»åŠ¡è¯†åˆ«ï¼šç®€å•ä»»åŠ¡è·³è¿‡å¤æ‚æµç¨‹
# ------------------------------------------------------------
import os, sys, asyncio, json, re, subprocess
from datetime import datetime
from typing import List, Literal, Dict, Any, Tuple

import traceback

import numpy as np
from rich.console import Console
from rich.panel import Panel
from rich.text import Text
from rich.live import Live
from rich.spinner import Spinner
from rich.table import Table
from rich.columns import Columns
import together

# ---------- å¸¸é‡ & é…ç½® ----------
REFERENCE_MODELS = [
    "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
    "mistralai/Mixtral-8x7B-Instruct-v0.1",
    "deepseek-ai/DeepSeek-V3",
]

AGGREGATOR_MODEL = "deepseek-ai/DeepSeek-V3"
CRITIC_MODELS = [
    "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
    "mistralai/Mixtral-8x7B-Instruct-v0.1",
    "deepseek-ai/DeepSeek-V3",
]

EXPERT_MODEL = "deepseek-ai/DeepSeek-V3"

State = Literal["DISCOVER_FILES", "INSTALL_TOOLS", "RUN_QC", "REPORT", "DONE"]
PIPELINE_ORDER: List[State] = ["DISCOVER_FILES","INSTALL_TOOLS","RUN_QC","REPORT","DONE"]

# ç®€åŒ–çš„æç¤ºè¯
PLANNER_SYSTEM_PROMPT = """You are a bioinformatics consultant. Output ONE concise sub-task to advance the pipeline.
States: DISCOVER_FILES â†’ INSTALL_TOOLS â†’ RUN_QC â†’ REPORT â†’ DONE
If state=="DONE" and validated==true, output TERMINATE."""

AGGREGATOR_SYSTEM_PROMPT = "Merge suggestions into ONE concise actionable sub-task."
SELF_CRITIQUE_SYSTEM_PROMPT = "Point out one concrete flaw or risk."
CRITIC_SYSTEM_PROMPT = """Score the plan 0-10. Return ONLY: {"score":N,"reason":"one sentence"}"""
EXPERT_SYSTEM_PROMPT = """React agent. Return ONLY JSON:
{"thought":"...","action":{"tool_name":"execute_bash|task_complete","parameters":{...}}}"""

# ç®€å•ä»»åŠ¡æ£€æµ‹
SIMPLE_TASK_PATTERNS = [
    r"generate.*fastq",
    r"create.*file",
    r"ç”Ÿæˆ.*æ–‡ä»¶",
    r"make.*reads"
]

API_KEY = os.getenv("TOGETHER_API_KEY") or os.getenv("TINA_API_KEY") 
if not API_KEY:
    API_KEY = "92d5979f5ffc69d344a37cc7b2cbef622b6d51b9a24f984d97a68ece985384fb"

TIMEOUT_CMD = 300  # å‡å°‘è¶…æ—¶æ—¶é—´
MAX_PLANNER_ROUNDS = 10  # å‡å°‘æœ€å¤§è½®æ•°
MAX_REACT_STEPS = 15  # å‡å°‘Reactæ­¥éª¤
CRITIC_PASS = 7  # é™ä½é€šè¿‡é—¨æ§›
MAX_TOKENS_PER_TURN = 3000  # å‡å°‘tokenæ•°

console = Console()
log_dir = "tina_logs"
os.makedirs(log_dir, exist_ok=True)
log_file = os.path.join(log_dir, f"tina_v17_{datetime.now():%Y%m%d_%H%M%S}.log")

def log(msg: str):
    """å¢å¼ºçš„æ—¥å¿—åŠŸèƒ½"""
    timestamp = datetime.now().strftime("%H:%M:%S.%f")[:-3]
    log_entry = f"[{timestamp}] {msg}"
    with open(log_file, "a", encoding="utf-8") as f:
        f.write(log_entry + "\n")
    # ä¹Ÿæ‰“å°åˆ°æ§åˆ¶å°ç”¨äºè°ƒè¯•
    if "ERROR" in msg or "WARN" in msg:
        console.print(f"[red]{log_entry}[/red]", highlight=False)

def panel(content: str, title: str, style: str = "white"):
    """æ˜¾ç¤ºé¢æ¿å¹¶è®°å½•æ—¥å¿—"""
    console.print(Panel(Text(content, overflow="fold"), title=title, border_style=style, expand=True))
    log(f"{title}: {content[:2000]}")

def run_bash(cmd: str) -> str:
    """æ‰§è¡Œbashå‘½ä»¤"""
    panel(f"$ {cmd}", "ğŸ’» æ‰§è¡Œå‘½ä»¤", "cyan")
    try:
        proc = subprocess.Popen(
            cmd, shell=True, 
            stdout=subprocess.PIPE, stderr=subprocess.PIPE,
            executable="/bin/bash", text=True, 
            encoding="utf-8", errors="replace"
        )
        out, err = proc.communicate(timeout=TIMEOUT_CMD)
        result = f"[STDOUT]\n{out}\n[STDERR]\n{err}".strip()
        style = "red" if err.strip() and proc.returncode != 0 else "green"
        panel(result[:1000], "ğŸ–¥ï¸ å‘½ä»¤è¾“å‡º", style)
        return result
    except subprocess.TimeoutExpired:
        proc.kill()
        return "[ERROR] Command timeout"
    except Exception as e:
        return f"[ERROR] {str(e)}"

# å¼‚æ­¥å®¢æˆ·ç«¯
async_client = together.AsyncClient(api_key=API_KEY, timeout=60)

async def llm(model: str, system: str, user: str, temperature: float = 0.3, max_tokens: int = 1000) -> str:
    """è°ƒç”¨LLM"""
    try:
        resp = await async_client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system},
                {"role": "user", "content": user}
            ],
            temperature=temperature,
            max_tokens=max_tokens
        )
        msg = resp.choices[0].message.content.strip()
        log(f"[{model}] Response: {msg[:200]}...")
        return msg
    except Exception as e:
        error_msg = f"ERROR calling {model}: {str(e)}"
        log(error_msg)
        return error_msg

def is_simple_task(goal: str) -> bool:
    """æ£€æµ‹æ˜¯å¦ä¸ºç®€å•ä»»åŠ¡"""
    goal_lower = goal.lower()
    return any(re.search(pattern, goal_lower) for pattern in SIMPLE_TASK_PATTERNS)

def parse_json_score(txt: str) -> Tuple[int, str]:
    """è§£æè¯„åˆ†JSONï¼Œè¿”å›(åˆ†æ•°, åŸå› )"""
    try:
        # é¦–å…ˆå°è¯•æå–JSON
        json_match = re.search(r'\{[^}]*"score"[^}]*\}', txt, re.DOTALL)
        if json_match:
            obj = json.loads(json_match.group(0))
            return int(obj.get("score", -1)), obj.get("reason", "No reason")
    except:
        pass
    
    # å¤‡ç”¨ï¼šæŸ¥æ‰¾æ•°å­—
    score_match = re.search(r'\b([0-9]|10)\b', txt)
    score = int(score_match.group(1)) if score_match else -1
    return score, "Failed to parse reason"

async def critic_vote_enhanced(goal: str, plan: str) -> Tuple[bool, List[Dict]]:
    """å¢å¼ºçš„è¯„å®¡å›¢æŠ•ç¥¨ï¼Œè¿”å›è¯¦ç»†ä¿¡æ¯"""
    prompt = f"Goal: {goal}\nPlan: {plan}"
    
    # åˆ›å»ºè¯„åˆ†è¡¨æ ¼
    score_table = Table(title="ğŸ—³ï¸ è¯„å®¡å›¢è¯¦ç»†è¯„åˆ†", show_header=True, expand=True)
    score_table.add_column("æ¨¡å‹", style="cyan", width=40)
    score_table.add_column("åˆ†æ•°", style="yellow", width=10)
    score_table.add_column("ç†ç”±", style="white", width=50)
    
    with Live(Spinner("dots", text="è¯„å®¡å›¢æŠ•ç¥¨ä¸­..."), console=console, transient=True):
        # å¹¶è¡Œè°ƒç”¨æ‰€æœ‰è¯„å®¡æ¨¡å‹
        tasks = []
        for i, model in enumerate(CRITIC_MODELS):
            task = llm(model, CRITIC_SYSTEM_PROMPT, prompt, temperature=0, max_tokens=200)
            tasks.append((i, model, task))
        
        # æ”¶é›†ç»“æœ
        results = []
        for i, model, task in tasks:
            try:
                response = await task
                score, reason = parse_json_score(response)
                results.append({
                    "model": model,
                    "score": score,
                    "reason": reason,
                    "response": response
                })
                
                # æ·»åŠ åˆ°è¡¨æ ¼
                model_short = model.split('/')[-1][:35] + "..." if len(model.split('/')[-1]) > 35 else model.split('/')[-1]
                score_table.add_row(
                    model_short,
                    str(score) if score >= 0 else "ERROR",
                    reason[:47] + "..." if len(reason) > 47 else reason
                )
                
            except Exception as e:
                log(f"ERROR in critic {i} ({model}): {str(e)}")
                results.append({
                    "model": model,
                    "score": -1,
                    "reason": f"Error: {str(e)}",
                    "response": str(e)
                })
                score_table.add_row(
                    model.split('/')[-1],
                    "ERROR",
                    str(e)[:50]
                )
    
    # æ˜¾ç¤ºè¯¦ç»†è¯„åˆ†è¡¨
    console.print(score_table)
    
    # è®¡ç®—æœ‰æ•ˆåˆ†æ•°
    valid_scores = [r["score"] for r in results if r["score"] >= 0]
    
    if valid_scores:
        mean = np.mean(valid_scores)
        std = np.std(valid_scores) if len(valid_scores) > 1 else 0
        median = np.median(valid_scores)
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        stats_panel = Panel(
            f"æœ‰æ•ˆè¯„åˆ†: {len(valid_scores)}/{len(CRITIC_MODELS)}\n"
            f"åˆ†æ•°åˆ—è¡¨: {valid_scores}\n"
            f"å¹³å‡åˆ†: {mean:.2f} Â± {std:.2f}\n"
            f"ä¸­ä½æ•°: {median:.1f}\n"
            f"{'âœ… é€šè¿‡' if mean >= CRITIC_PASS else 'âŒ æœªé€šè¿‡'} (åŠæ ¼çº¿: {CRITIC_PASS})",
            title="ğŸ“Š è¯„åˆ†ç»Ÿè®¡",
            border_style="green" if mean >= CRITIC_PASS else "red"
        )
        console.print(stats_panel)
        
        passed = mean >= CRITIC_PASS
    else:
        panel("æ‰€æœ‰è¯„å®¡æ¨¡å‹éƒ½å¤±è´¥äº†ï¼", "âš ï¸ è­¦å‘Š", "yellow")
        passed = False
    
    return passed, results

async def simple_task_execution(goal: str) -> bool:
    """ç›´æ¥æ‰§è¡Œç®€å•ä»»åŠ¡"""
    panel(f"æ£€æµ‹åˆ°ç®€å•ä»»åŠ¡ï¼Œç›´æ¥æ‰§è¡Œï¼š{goal}", "ğŸš€ å¿«é€Ÿæ¨¡å¼", "green")
    
    # å¯¹äºç”Ÿæˆfastqæ–‡ä»¶çš„ä»»åŠ¡
    if "fastq" in goal.lower() or "generate" in goal.lower():
        # ç”Ÿæˆä¸€ä¸ªç®€å•çš„fastqæ–‡ä»¶
        cmd = """
# ç”Ÿæˆéšæœºfastqæ–‡ä»¶
cat > generate_random_fastq.py << 'EOF'
import random
import sys

def generate_random_seq(length):
    return ''.join(random.choice('ACGT') for _ in range(length))

def generate_random_qual(length):
    return ''.join(chr(random.randint(33, 73)) for _ in range(length))

# ç”Ÿæˆ1000ä¸ªreads
num_reads = 1000
read_length = 150

with open('random_reads_R1.fastq', 'w') as f1, open('random_reads_R2.fastq', 'w') as f2:
    for i in range(num_reads):
        seq1 = generate_random_seq(read_length)
        seq2 = generate_random_seq(read_length)
        qual1 = generate_random_qual(read_length)
        qual2 = generate_random_qual(read_length)
        
        # R1
        f1.write(f'@read_{i}/1\\n{seq1}\\n+\\n{qual1}\\n')
        # R2
        f2.write(f'@read_{i}/2\\n{seq2}\\n+\\n{qual2}\\n')

print(f"Generated {num_reads} paired-end reads")
print("Files: random_reads_R1.fastq, random_reads_R2.fastq")
EOF

python generate_random_fastq.py
ls -lh random_reads_*.fastq
head -n 8 random_reads_R1.fastq
"""
        result = run_bash(cmd)
        
        if "Generated" in result and "random_reads" in result:
            panel("âœ… æˆåŠŸç”ŸæˆéšæœºFASTQæ–‡ä»¶ï¼", "ğŸ‰ ä»»åŠ¡å®Œæˆ", "green")
            return True
    
    return False

async def react_execute_improved(sub_task: str, project_state: Dict[str, Any]) -> bool:
    """æ”¹è¿›çš„ReActæ‰§è¡Œï¼Œè¿”å›æ˜¯å¦æˆåŠŸ"""
    history = ""
    success = False
    
    for step in range(1, min(MAX_REACT_STEPS, 5) + 1):  # é™åˆ¶æ­¥éª¤æ•°
        if step == 1:
            panel(f"å­ä»»åŠ¡: {sub_task}", "ğŸ¯ å¼€å§‹æ‰§è¡Œ", "bold green")
        
        prompt = f"Step {step}\nTask: {sub_task}\nHistory: {history[-1000:]}"  # é™åˆ¶å†å²é•¿åº¦
        
        with Live(Spinner("bouncingBar", text=f"æ€è€ƒæ­¥éª¤ {step}..."), console=console, transient=True):
            resp = await llm(EXPERT_MODEL, EXPERT_SYSTEM_PROMPT, prompt, temperature=0)
        
        # è§£æå“åº”
        try:
            # å°è¯•å¤šç§JSONæå–æ–¹æ³•
            data = None
            
            # æ–¹æ³•1ï¼šç›´æ¥è§£æ
            try:
                data = json.loads(resp)
            except:
                # æ–¹æ³•2ï¼šæŸ¥æ‰¾JSONå—
                json_match = re.search(r'\{.*"thought".*"action".*\}', resp, re.DOTALL)
                if json_match:
                    data = json.loads(json_match.group(0))
            
            if not data:
                log(f"Failed to parse JSON from: {resp[:200]}")
                continue
                
        except Exception as e:
            panel(f"JSONè§£æå¤±è´¥: {str(e)}\nå“åº”: {resp[:200]}", "âŒ é”™è¯¯", "red")
            continue
        
        thought = data.get("thought", "")
        action = data.get("action", {})
        tool = action.get("tool_name", "")
        params = action.get("parameters", {})
        
        panel(thought[:200], f"ğŸ¤” æ€è€ƒ ({step})", "green")
        
        if tool == "execute_bash":
            cmd = params.get("cmd") or params.get("command") or params.get("script", "")
            if cmd:
                result = run_bash(cmd)
                history += f"\n[Step{step}] {cmd}\n{result[:500]}"
                
                # æ£€æŸ¥æ˜¯å¦æˆåŠŸ
                if "error" not in result.lower() or "fastq" in result.lower():
                    success = True
                    
        elif tool == "task_complete":
            panel(params.get("reason", "å®Œæˆ"), "âœ… å­ä»»åŠ¡å®Œæˆ", "bold green")
            success = True
            break
    
    return success

async def main():
    """ä¸»å‡½æ•°"""
    console.print(Panel(
        "[bold cyan]Tina v17.0 â€“ æ”¹è¿›ç‰ˆ MoA Agent[/bold cyan]\n"
        "â€¢ è¯¦ç»†è¯„åˆ†æ˜¾ç¤º\n"
        "â€¢ ç®€å•ä»»åŠ¡å¿«é€Ÿæ‰§è¡Œ\n"
        "â€¢ æ›´é«˜æ•ˆçš„æ‰§è¡Œæµç¨‹",
        border_style="blue"
    ))
    
    while True:
        try:
            goal = console.input("\n[bold yellow]ğŸ§‘ è¯·è¾“å…¥ä»»åŠ¡ç›®æ ‡ï¼š[/bold yellow]").strip()
            if goal.lower() in ("exit", "quit", "q"):
                break
            
            log(f"User goal: {goal}")
            
            # æ£€æµ‹ç®€å•ä»»åŠ¡
            if is_simple_task(goal):
                success = await simple_task_execution(goal)
                if success:
                    continue
            
            # å¤æ‚ä»»åŠ¡æµç¨‹
            project_state = {
                "user_goal": goal,
                "state": "DISCOVER_FILES",
                "validated": False
            }
            
            for round_id in range(1, MAX_PLANNER_ROUNDS + 1):
                panel(f"ç¬¬ {round_id}/{MAX_PLANNER_ROUNDS} è½®", "â­ è§„åˆ’è½®æ¬¡", "bold magenta")
                
                # è§„åˆ’æ­¥éª¤
                payload = json.dumps(project_state, indent=2)
                
                # è·å–ä¸“å®¶æ„è§ï¼ˆç®€åŒ–ç‰ˆï¼‰
                with Live(Spinner("dots", text="ä¸“å®¶æ€è€ƒä¸­..."), console=console, transient=True):
                    opinions = await asyncio.gather(*[
                        llm(m, PLANNER_SYSTEM_PROMPT, 
                            f"State: {project_state}\nGoal: {goal}\nGive ONE next action.")
                        for m in REFERENCE_MODELS[:2]  # åªç”¨2ä¸ªæ¨¡å‹åŠ å¿«é€Ÿåº¦
                    ])
                
                # èšåˆæ„è§
                final_plan = await llm(
                    AGGREGATOR_MODEL, 
                    AGGREGATOR_SYSTEM_PROMPT,
                    "\n".join(opinions)
                )
                
                panel(final_plan, "ğŸ“„ æœ€ç»ˆæ–¹æ¡ˆ", "blue")
                
                # æ£€æŸ¥æ˜¯å¦å®Œæˆ
                if "TERMINATE" in final_plan.upper():
                    panel("ğŸ† ä»»åŠ¡å®Œæˆï¼", "ğŸ‰ æˆåŠŸ", "bold green")
                    break
                
                # è¯„å®¡æŠ•ç¥¨
                passed, vote_details = await critic_vote_enhanced(goal, final_plan)
                
                if not passed:
                    panel("æ–¹æ¡ˆæœªé€šè¿‡ï¼Œç»§ç»­ä¼˜åŒ–...", "âŒ éœ€è¦æ”¹è¿›", "red")
                    continue
                
                # æ‰§è¡Œè®¡åˆ’
                success = await react_execute_improved(final_plan, project_state)
                
                # æ›´æ–°çŠ¶æ€
                if success:
                    current_idx = PIPELINE_ORDER.index(project_state["state"])
                    if current_idx < len(PIPELINE_ORDER) - 1:
                        project_state["state"] = PIPELINE_ORDER[current_idx + 1]
                        
                    # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾DONEçŠ¶æ€
                    if project_state["state"] == "DONE":
                        project_state["validated"] = True
                        panel("âœ… æµç¨‹å®Œæˆï¼Œä»»åŠ¡æˆåŠŸï¼", "ğŸŠ å®Œæˆ", "bold green")
                        break
                        
            else:
                panel("è¾¾åˆ°æœ€å¤§è½®æ¬¡é™åˆ¶", "âš ï¸ è¶…æ—¶", "yellow")
                
        except KeyboardInterrupt:
            panel("ç”¨æˆ·ä¸­æ–­", "âš ï¸ é€€å‡º", "yellow")
            break
        except Exception as e:
            panel(f"é”™è¯¯: {str(e)}\n{traceback.format_exc()}", "âŒ å¼‚å¸¸", "red")
            
    # æ˜¾ç¤ºæ—¥å¿—ä½ç½®
    panel(f"è¯¦ç»†æ—¥å¿—ä¿å­˜åœ¨: {log_file}", "ğŸ“ æ—¥å¿—æ–‡ä»¶", "dim")

if __name__ == "__main__":
    asyncio.run(main())
